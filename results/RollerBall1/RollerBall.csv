Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
10000,1.4233135,9.16914749661705,0.4558611,0.470189701897019,0.470189701897019,0.12857117,0.23554493,0.00029621905,0.19873968,0.0004938245,1.0
20000,1.4310969,11.042067307692308,0.7890051,0.8293269230769231,0.8293269230769231,0.055554833,0.23888049,0.00029100073,0.19700025,0.0004853012,1.0
30000,1.4012123,8.98,0.89184445,0.926,0.926,0.02987451,0.24314407,0.00028500156,0.19500053,0.00047550254,1.0
40000,1.3818,8.910802775024777,0.9227558,0.9613478691774033,0.9613478691774033,0.019269912,0.23783381,0.00027899636,0.19299878,0.00046569412,1.0
50000,1.3671297,7.17483660130719,0.95798016,0.9893790849673203,0.9893790849673203,0.0066638375,0.2477613,0.00027303342,0.19101115,0.00045595458,1.0
